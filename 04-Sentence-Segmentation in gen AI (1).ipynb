{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16537b04-3cbe-442d-ad1d-93d5f09a0d5d",
   "metadata": {},
   "source": [
    "Sentence Segmentation \n",
    "\n",
    "in spacy basis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13c2e17f-7190-4cb9-b622-6c2b1c5d0a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform standard imports \n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49441e7b-d87d-40b6-b364-a52f9998f2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the firstn= sentence.\n",
      "this is another sentence.\n",
      "this is the last sentence .\n"
     ]
    }
   ],
   "source": [
    "#from spacy basics:\n",
    "doc = nlp(u'This is the firstn= sentence. this is another sentence. this is the last sentence .')\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9718157f-6c15-4850-a9bf-ae9548449f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n"
     ]
    }
   ],
   "source": [
    "print(doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "256f5b94-aaa0-47a0-b263-dc5de4b58d37",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(doc\u001b[38;5;241m.\u001b[39msents[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(doc.sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1cab23c-18bf-4c87-a045-e0832ebab6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is the firstn= sentence.,\n",
       " this is another sentence.,\n",
       " this is the last sentence .]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sent = [sent for sent in doc.sents]\n",
    "doc_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d38cf8-d721-46a9-957d-1b7b1e3f433e",
   "metadata": {},
   "source": [
    "sents and spans \n",
    "\n",
    "At first glance it looks each sent contains text from the original Doc object. in fact they're just Spans With start \n",
    "and end token pointers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1b91dd5-6c1d-4330-b9c3-41af4a732f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_sent[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "826a58b0-68b6-4a9e-aca3-122bca477ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 11\n"
     ]
    }
   ],
   "source": [
    "print(doc_sent[1].start, doc_sent[1].end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7339bca2-4f0e-4ba2-be89-a89b66b6ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a248d1a-1d78-4cee-8094-fd2d3406808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True  This\n",
      "False  is\n",
      "False  a\n",
      "False  sentence\n",
      "False  .\n",
      "True  This\n",
      "False  is\n",
      "False  a\n",
      "False  sentence\n",
      "False  .\n",
      "True  This\n",
      "False  is\n",
      "False  a\n",
      "False  sentence\n",
      "False  .\n"
     ]
    }
   ],
   "source": [
    "# Praising the segmentation start tokens happens during the nlp pipeline\n",
    "doc2 = nlp(u'This is a sentence. This is a sentence. This is a sentence.')\n",
    "\n",
    "for token in doc2:\n",
    "    print(token.is_sent_start, ' '+token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56ba9746-167e-46fd-863e-97c906486410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Management is doing things right; leadership is doing the right things.\"\n",
      "-Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "# SPACY's Default Behaviour\n",
    "doc3 = nlp(u' \"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n",
    "\n",
    "for sent in doc3.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e8432df-86af-4c0f-bd1e-f02e08ef91ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<string>:6\u001b[1;36m\u001b[0m\n\u001b[1;33m    return doc\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#ADD A NEW RULE TO PIPELINE\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == ';':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "     return doc\n",
    "\n",
    "nlp.add_pipe(set_custom_boundaries, before='parser')\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "087f7a25-ab5e-4f5f-a695-17d62055b9ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <function set_custom_boundaries at 0x000001D8FD9B96C0> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mpipe_names:\n\u001b[1;32m---> 13\u001b[0m     nlp\u001b[38;5;241m.\u001b[39madd_pipe(set_custom_boundaries, before\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m     nlp\u001b[38;5;241m.\u001b[39madd_pipe(set_custom_boundaries, last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\language.py:810\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    808\u001b[0m     bad_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrepr\u001b[39m(factory_name)\n\u001b[0;32m    809\u001b[0m     err \u001b[38;5;241m=\u001b[39m Errors\u001b[38;5;241m.\u001b[39mE966\u001b[38;5;241m.\u001b[39mformat(component\u001b[38;5;241m=\u001b[39mbad_val, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m--> 810\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[0;32m    811\u001b[0m name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m factory_name\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_names:\n",
      "\u001b[1;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <function set_custom_boundaries at 0x000001D8FD9B96C0> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == ';':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "if 'parser' in nlp.pipe_names:\n",
    "    nlp.add_pipe(set_custom_boundaries, before='parser')\n",
    "else:\n",
    "    nlp.add_pipe(set_custom_boundaries, last=True)\n",
    "\n",
    "# Print the pipeline component names\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "# Example usage\n",
    "doc = nlp(\"This is one sentence; this is another; and yet another.\")\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9872b78e-cffd-4b47-8c1a-fc7b92d8b041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
